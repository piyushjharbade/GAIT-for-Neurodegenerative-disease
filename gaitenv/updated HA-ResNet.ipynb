{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996bd2b-bc08-4017-af56-1c87a280fba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ccce0f-c562-46d6-9079-0cf2750f29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define BConvLSTM and Hidden Attention Module\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ConvLSTM Cell (single direction)\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size=3, padding=1):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        # Convolution for input-to-state and state-to-state transitions\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=input_dim + hidden_dim,\n",
    "            out_channels=4 * hidden_dim,  # For input, forget, cell, output gates\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # [batch, input_dim + hidden_dim, height, width]\n",
    "        combined_conv = self.conv(combined)\n",
    "        # Split into gates\n",
    "        cc_i, cc_f, cc_c, cc_o = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        # Gate activations\n",
    "        i = torch.sigmoid(cc_i)  # Input gate\n",
    "        f = torch.sigmoid(cc_f)  # Forget gate\n",
    "        o = torch.sigmoid(cc_o)  # Output gate\n",
    "        c_next = f * c_cur + i * torch.tanh(cc_c)  # Cell state\n",
    "        h_next = o * torch.tanh(c_next)  # Hidden state\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "# Bidirectional ConvLSTM\n",
    "class BConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size=3, padding=1):\n",
    "        super(BConvLSTM, self).__init__()\n",
    "        self.forward_cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, padding)\n",
    "        self.backward_cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, padding)\n",
    "        # Final convolution to combine forward and backward outputs\n",
    "        self.conv_out = nn.Conv2d(hidden_dim * 2, hidden_dim, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, channels, height, width]\n",
    "        batch_size, _, height, width = x.size()\n",
    "        # Initialize hidden states\n",
    "        h_f, c_f = self.forward_cell.init_hidden(batch_size, (height, width))\n",
    "        h_b, c_b = self.backward_cell.init_hidden(batch_size, (height, width))\n",
    "        \n",
    "        # Forward pass\n",
    "        h_forward = []\n",
    "        for t in range(1):  # Single time step (as input is a single feature map)\n",
    "            h_f, c_f = self.forward_cell(x, cur_state=[h_f, c_f])\n",
    "            h_forward.append(h_f)\n",
    "        h_forward = h_forward[0]  # [batch, hidden_dim, height, width]\n",
    "        \n",
    "        # Backward pass\n",
    "        h_backward = []\n",
    "        for t in range(1):  # Single time step\n",
    "            h_b, c_b = self.backward_cell(x, cur_state=[h_b, c_b])\n",
    "            h_backward.append(h_b)\n",
    "        h_backward = h_backward[0]  # [batch, hidden_dim, height, width]\n",
    "        \n",
    "        # Combine forward and backward\n",
    "        h_combined = torch.cat([h_forward, h_backward], dim=1)  # [batch, hidden_dim*2, height, width]\n",
    "        output = self.conv_out(h_combined)  # [batch, hidden_dim, height, width]\n",
    "        return output\n",
    "\n",
    "# Hidden Attention Module with BConvLSTM\n",
    "class HiddenAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(HiddenAttentionModule, self).__init__()\n",
    "        # First Conv Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Second Conv Layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        # SE Block\n",
    "        self.se_block = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels // 16, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels // 16, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # Shortcut Connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        # BConvLSTM\n",
    "        self.bconvlstm = BConvLSTM(input_dim=out_channels, hidden_dim=out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        # Conv Path\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # SE Block\n",
    "        se = self.se_block(out)\n",
    "        out = out * se\n",
    "        # Shortcut\n",
    "        identity = self.shortcut(identity)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        # BConvLSTM\n",
    "        out = self.bconvlstm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d612b-8b2d-4bd0-baa7-20c9601c0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define HA-ResNet Model (with Dropout)\n",
    "class HA_ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(HA_ResNet, self).__init__()\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.ham1 = HiddenAttentionModule(64, 64, stride=1)\n",
    "        self.ham2 = HiddenAttentionModule(64, 128, stride=2)\n",
    "        self.ham3 = HiddenAttentionModule(128, 256, stride=2)\n",
    "        self.ham4 = HiddenAttentionModule(256, 512, stride=2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.ham1(x)\n",
    "        x = self.ham2(x)\n",
    "        x = self.ham3(x)\n",
    "        x = self.ham4(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb5bd5-011b-4ef8-93f2-09527121f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Custom Dataset (Updated to Preload Images)\n",
    "class GaitGAFDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # Preload images into memory\n",
    "        print(\"Preloading images into memory...\")\n",
    "        self.images = []\n",
    "        for img_path in tqdm(image_paths, desc=\"Loading images\"):\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            self.images.append(image)\n",
    "        print(f\"Loaded {len(self.images)} images into memory.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea130a8b-aea0-4b96-a58f-51e02ffcdcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset mapping for HA-ResNet training...\n",
      "Collected 52 images for als/L_Stride\n",
      "Collected 52 images for als/R_Stride\n",
      "Collected 52 images for als/L_Swing\n",
      "Collected 52 images for als/R_Swing\n",
      "Collected 52 images for als/L_Swing%\n",
      "Collected 52 images for als/R_Swing%\n",
      "Collected 52 images for als/L_Stance\n",
      "Collected 52 images for als/R_Stance\n",
      "Collected 52 images for als/L_Stance%\n",
      "Collected 52 images for als/R_Stance%\n",
      "Collected 52 images for als/DoubleSupport\n",
      "Collected 52 images for als/DoubleSupport%\n",
      "Collected 64 images for control/L_Stride\n",
      "Collected 64 images for control/R_Stride\n",
      "Collected 64 images for control/L_Swing\n",
      "Collected 64 images for control/R_Swing\n",
      "Collected 64 images for control/L_Swing%\n",
      "Collected 64 images for control/R_Swing%\n",
      "Collected 64 images for control/L_Stance\n",
      "Collected 64 images for control/R_Stance\n",
      "Collected 64 images for control/L_Stance%\n",
      "Collected 64 images for control/R_Stance%\n",
      "Collected 64 images for control/DoubleSupport\n",
      "Collected 64 images for control/DoubleSupport%\n",
      "Collected 80 images for hunt/L_Stride\n",
      "Collected 80 images for hunt/R_Stride\n",
      "Collected 80 images for hunt/L_Swing\n",
      "Collected 80 images for hunt/R_Swing\n",
      "Collected 80 images for hunt/L_Swing%\n",
      "Collected 80 images for hunt/R_Swing%\n",
      "Collected 80 images for hunt/L_Stance\n",
      "Collected 80 images for hunt/R_Stance\n",
      "Collected 80 images for hunt/L_Stance%\n",
      "Collected 80 images for hunt/R_Stance%\n",
      "Collected 80 images for hunt/DoubleSupport\n",
      "Collected 80 images for hunt/DoubleSupport%\n",
      "Collected 60 images for park/L_Stride\n",
      "Collected 60 images for park/R_Stride\n",
      "Collected 60 images for park/L_Swing\n",
      "Collected 60 images for park/R_Swing\n",
      "Collected 60 images for park/L_Swing%\n",
      "Collected 60 images for park/R_Swing%\n",
      "Collected 60 images for park/L_Stance\n",
      "Collected 60 images for park/R_Stance\n",
      "Collected 60 images for park/L_Stance%\n",
      "Collected 60 images for park/R_Stance%\n",
      "Collected 60 images for park/DoubleSupport\n",
      "Collected 60 images for park/DoubleSupport%\n",
      "\n",
      "Total images in dataset: 3072 (expected 3072)\n",
      "Example entry: ('c:\\\\Users\\\\piyus\\\\mlenv\\\\gaitenv\\\\gait-in-neurodegenerative-disease-database-1.0.0\\\\gaf_images_augmented\\\\als\\\\L_Stride\\\\als1.png', 0)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create Dataset Mapping for HA-ResNet Training\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    \"als\": 0,\n",
    "    \"control\": 1,\n",
    "    \"hunt\": 2,\n",
    "    \"park\": 3\n",
    "}\n",
    "\n",
    "# Base directory\n",
    "base_dir = os.path.join(os.getcwd(), \"gait-in-neurodegenerative-disease-database-1.0.0\", \"gaf_images_augmented\")\n",
    "\n",
    "# Collect image paths and labels\n",
    "dataset_mapping = []\n",
    "groups = [\"als\", \"control\", \"hunt\", \"park\"]\n",
    "feature_columns = [\n",
    "    \"L_Stride\", \"R_Stride\", \"L_Swing\", \"R_Swing\", \"L_Swing%\", \"R_Swing%\", \n",
    "    \"L_Stance\", \"R_Stance\", \"L_Stance%\", \"R_Stance%\", \"DoubleSupport\", \"DoubleSupport%\"\n",
    "]\n",
    "\n",
    "print(\"Creating dataset mapping for HA-ResNet training...\")\n",
    "for group in groups:\n",
    "    label = label_mapping[group]\n",
    "    for feature in feature_columns:\n",
    "        feature_dir = os.path.join(base_dir, group, feature)\n",
    "        if not os.path.exists(feature_dir):\n",
    "            print(f\"Warning: Directory not found: {feature_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # Find all .png files in the feature directory\n",
    "        image_paths = glob.glob(os.path.join(feature_dir, \"*.png\"))\n",
    "        for image_path in image_paths:\n",
    "            dataset_mapping.append((image_path, label))\n",
    "        \n",
    "        print(f\"Collected {len(image_paths)} images for {group}/{feature}\")\n",
    "\n",
    "# Verify total images\n",
    "print(f\"\\nTotal images in dataset: {len(dataset_mapping)} (expected 3072)\")\n",
    "if len(dataset_mapping) != 3072:\n",
    "    print(f\"Warning: Expected 3072 images (64 subjects × 12 features × 4 versions), but found {len(dataset_mapping)}.\")\n",
    "\n",
    "# Example entry\n",
    "if dataset_mapping:\n",
    "    print(f\"Example entry: {dataset_mapping[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1388e-7ecc-404c-8368-82c0cdbcfb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading images into memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47033abc0e94e49984de64eefb04b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images:   0%|          | 0/2149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2149 images into memory.\n",
      "Preloading images into memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c9f0a6f1e045fdb31ba3545779beec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images:   0%|          | 0/308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 308 images into memory.\n",
      "Preloading images into memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28d71ccec042819521c43fc3fbe2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images:   0%|          | 0/615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 615 images into memory.\n",
      "Training dataset size: 2149\n",
      "Validation dataset size: 308\n",
      "Test dataset size: 615\n",
      "Training class distribution: Counter({2: 672, 1: 537, 3: 504, 0: 436})\n",
      "Validation class distribution: Counter({2: 96, 1: 77, 3: 72, 0: 63})\n",
      "Test class distribution: Counter({2: 192, 1: 154, 3: 144, 0: 125})\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Prepare Dataset and DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Extract image paths and labels from dataset_mapping (from Cell 5)\n",
    "image_paths = [item[0] for item in dataset_mapping]\n",
    "labels = [item[1] for item in dataset_mapping]\n",
    "\n",
    "# Split dataset into train, validation, and test sets (70% train, 10% val, 20% test)\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths, train_val_labels, test_size=0.1/0.8, stratify=train_val_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = GaitGAFDataset(train_paths, train_labels, transform=transform)\n",
    "val_dataset = GaitGAFDataset(val_paths, val_labels, transform=transform)\n",
    "test_dataset = GaitGAFDataset(test_paths, test_labels, transform=transform)\n",
    "\n",
    "# Compute class weights for WeightedRandomSampler (to handle class imbalance)\n",
    "label_counts = Counter(train_labels)\n",
    "num_samples = len(train_labels)\n",
    "class_weights = {i: num_samples / (len(label_counts) * count) for i, count in label_counts.items()}\n",
    "sample_weights = [class_weights[label] for label in train_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders with optimized settings\n",
    "batch_size = 32 \n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, sampler=sampler, num_workers=0, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# Print dataset sizes and class distributions\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Training class distribution: {Counter(train_labels)}\")\n",
    "print(f\"Validation class distribution: {Counter(val_labels)}\")\n",
    "print(f\"Test class distribution: {Counter(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27796aeb-ff7d-433d-850d-4c59d1ba4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training and Evaluation Functions (Updated for Mixed Precision)\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    best_val_f1 = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_true = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():  # Mixed precision\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_preds.extend(preds.tolist())\n",
    "            train_true.extend(labels.tolist())\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = accuracy_score(train_true, train_preds)\n",
    "        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(\n",
    "            train_true, train_preds, average='weighted', zero_division=0\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.tolist())\n",
    "                val_true.extend(labels.tolist())\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
    "            val_true, val_preds, average='weighted', zero_division=0\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train - Loss: {epoch_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
    "        print(f\"Unique predicted classes (val): {np.unique(val_preds)}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'best_ha_resnet.pth')\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            preds.extend(predicted.tolist())\n",
    "            true.extend(labels.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(true, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true, preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    print(f\"Unique predicted classes (test): {np.unique(preds)}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ALS', 'Control', 'Huntington', 'Parkinson'],\n",
    "                yticklabels=['ALS', 'Control', 'Huntington', 'Parkinson'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135c325-d6e5-40ec-ac3c-46daa5fc5fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # For mixed precision training\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train - Loss: 1.2107, Accuracy: 0.4537, F1: 0.4498\n",
      "Val   - Loss: 1.1892, Accuracy: 0.5000, F1: 0.4962\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "Train - Loss: 0.8368, Accuracy: 0.6822, F1: 0.6819\n",
      "Val   - Loss: 1.1782, Accuracy: 0.6331, F1: 0.6368\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "Train - Loss: 0.5506, Accuracy: 0.7957, F1: 0.7945\n",
      "Val   - Loss: 0.7862, Accuracy: 0.7273, F1: 0.7288\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "Train - Loss: 0.3805, Accuracy: 0.8571, F1: 0.8563\n",
      "Val   - Loss: 0.6922, Accuracy: 0.7662, F1: 0.7659\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "Train - Loss: 0.2981, Accuracy: 0.8986, F1: 0.8982\n",
      "Val   - Loss: 0.6079, Accuracy: 0.7922, F1: 0.7909\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "Train - Loss: 0.1961, Accuracy: 0.9339, F1: 0.9338\n",
      "Val   - Loss: 0.5214, Accuracy: 0.8571, F1: 0.8571\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "Train - Loss: 0.1714, Accuracy: 0.9451, F1: 0.9449\n",
      "Val   - Loss: 0.5791, Accuracy: 0.8442, F1: 0.8463\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "Train - Loss: 0.1397, Accuracy: 0.9544, F1: 0.9543\n",
      "Val   - Loss: 0.6724, Accuracy: 0.7565, F1: 0.7592\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "Train - Loss: 0.1283, Accuracy: 0.9549, F1: 0.9548\n",
      "Val   - Loss: 0.5137, Accuracy: 0.8442, F1: 0.8432\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "Train - Loss: 0.0739, Accuracy: 0.9721, F1: 0.9721\n",
      "Val   - Loss: 0.6315, Accuracy: 0.8312, F1: 0.8327\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "Train - Loss: 0.1197, Accuracy: 0.9553, F1: 0.9552\n",
      "Val   - Loss: 0.6126, Accuracy: 0.8539, F1: 0.8537\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "Train - Loss: 0.0855, Accuracy: 0.9702, F1: 0.9702\n",
      "Val   - Loss: 0.5956, Accuracy: 0.8506, F1: 0.8512\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "Train - Loss: 0.1506, Accuracy: 0.9456, F1: 0.9454\n",
      "Val   - Loss: 0.5241, Accuracy: 0.8539, F1: 0.8548\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "Train - Loss: 0.0705, Accuracy: 0.9739, F1: 0.9740\n",
      "Val   - Loss: 0.5034, Accuracy: 0.8669, F1: 0.8675\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "Train - Loss: 0.0884, Accuracy: 0.9711, F1: 0.9711\n",
      "Val   - Loss: 0.5548, Accuracy: 0.8701, F1: 0.8710\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "Train - Loss: 0.0524, Accuracy: 0.9832, F1: 0.9833\n",
      "Val   - Loss: 0.7451, Accuracy: 0.8539, F1: 0.8539\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "Train - Loss: 0.0371, Accuracy: 0.9874, F1: 0.9874\n",
      "Val   - Loss: 0.5902, Accuracy: 0.8474, F1: 0.8476\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "Train - Loss: 0.0222, Accuracy: 0.9930, F1: 0.9930\n",
      "Val   - Loss: 0.5752, Accuracy: 0.8669, F1: 0.8670\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "Train - Loss: 0.0313, Accuracy: 0.9912, F1: 0.9912\n",
      "Val   - Loss: 0.5769, Accuracy: 0.8799, F1: 0.8799\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n",
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "Train - Loss: 0.1235, Accuracy: 0.9563, F1: 0.9561\n",
      "Val   - Loss: 0.5422, Accuracy: 0.8766, F1: 0.8774\n",
      "Unique predicted classes (val): [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\AppData\\Local\\Temp\\ipykernel_15796\\2061534308.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m num_epochs = \u001b[32m50\u001b[39m  \u001b[38;5;66;03m# Restored to original value\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Load best model and evaluate\u001b[39;00m\n\u001b[32m     20\u001b[39m model.load_state_dict(torch.load(\u001b[33m'\u001b[39m\u001b[33mbest_ha_resnet.pth\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[39m\n\u001b[32m     17\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m     18\u001b[39m scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m scaler.update()\n\u001b[32m     21\u001b[39m running_loss += loss.item() * inputs.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\piyus\\mlenv\\gaitenv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\piyus\\mlenv\\gaitenv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:355\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\piyus\\mlenv\\gaitenv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:355\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 8: Main Execution (Train and Evaluate Model)\n",
    "# Initialize model\n",
    "model = HA_ResNet(num_classes=4).to(device)\n",
    "\n",
    "# Class weights for imbalanced dataset (inverse of class frequencies)\n",
    "class_weights = torch.tensor([3072/624, 3072/768, 3072/960, 3072/720], dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.0001  # As per paper\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50  # Restored to original value\n",
    "\n",
    "# Train model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load('best_ha_resnet.pth'))\n",
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b462a1-7098-4124-aa63-8146cb920c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
