{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb16394-c69d-42f0-8c47-48fcb0a7d2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40f2b4c-c693-4491-acb6-d6cd570e7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define BConvLSTM and Hidden Attention Module\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ConvLSTM Cell (single direction)\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size=3, padding=1):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        # Convolution for input-to-state and state-to-state transitions\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=input_dim + hidden_dim,\n",
    "            out_channels=4 * hidden_dim,  # For input, forget, cell, output gates\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # [batch, input_dim + hidden_dim, height, width]\n",
    "        combined_conv = self.conv(combined)\n",
    "        # Split into gates\n",
    "        cc_i, cc_f, cc_c, cc_o = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        # Gate activations\n",
    "        i = torch.sigmoid(cc_i)  # Input gate\n",
    "        f = torch.sigmoid(cc_f)  # Forget gate\n",
    "        o = torch.sigmoid(cc_o)  # Output gate\n",
    "        c_next = f * c_cur + i * torch.tanh(cc_c)  # Cell state\n",
    "        h_next = o * torch.tanh(c_next)  # Hidden state\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "# Bidirectional ConvLSTM\n",
    "class BConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size=3, padding=1):\n",
    "        super(BConvLSTM, self).__init__()\n",
    "        self.forward_cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, padding)\n",
    "        self.backward_cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, padding)\n",
    "        # Final convolution to combine forward and backward outputs\n",
    "        self.conv_out = nn.Conv2d(hidden_dim * 2, hidden_dim, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, channels, height, width]\n",
    "        batch_size, _, height, width = x.size()\n",
    "        # Initialize hidden states\n",
    "        h_f, c_f = self.forward_cell.init_hidden(batch_size, (height, width))\n",
    "        h_b, c_b = self.backward_cell.init_hidden(batch_size, (height, width))\n",
    "        \n",
    "        # Forward pass\n",
    "        h_forward = []\n",
    "        for t in range(1):  # Single time step (as input is a single feature map)\n",
    "            h_f, c_f = self.forward_cell(x, cur_state=[h_f, c_f])\n",
    "            h_forward.append(h_f)\n",
    "        h_forward = h_forward[0]  # [batch, hidden_dim, height, width]\n",
    "        \n",
    "        # Backward pass\n",
    "        h_backward = []\n",
    "        for t in range(1):  # Single time step\n",
    "            h_b, c_b = self.backward_cell(x, cur_state=[h_b, c_b])\n",
    "            h_backward.append(h_b)\n",
    "        h_backward = h_backward[0]  # [batch, hidden_dim, height, width]\n",
    "        \n",
    "        # Combine forward and backward\n",
    "        h_combined = torch.cat([h_forward, h_backward], dim=1)  # [batch, hidden_dim*2, height, width]\n",
    "        output = self.conv_out(h_combined)  # [batch, hidden_dim, height, width]\n",
    "        return output\n",
    "\n",
    "# Hidden Attention Module with BConvLSTM\n",
    "class HiddenAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(HiddenAttentionModule, self).__init__()\n",
    "        # First Conv Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Second Conv Layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        # SE Block\n",
    "        self.se_block = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels // 16, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels // 16, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # Shortcut Connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        # BConvLSTM\n",
    "        self.bconvlstm = BConvLSTM(input_dim=out_channels, hidden_dim=out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        # Conv Path\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # SE Block\n",
    "        se = self.se_block(out)\n",
    "        out = out * se\n",
    "        # Shortcut\n",
    "        identity = self.shortcut(identity)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        # BConvLSTM\n",
    "        out = self.bconvlstm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d171b0d9-683f-4265-8473-ebc1a682abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define HA-ResNet Model (with Dropout)\n",
    "class HA_ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(HA_ResNet, self).__init__()\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.ham1 = HiddenAttentionModule(64, 64, stride=1)\n",
    "        self.ham2 = HiddenAttentionModule(64, 128, stride=2)\n",
    "        self.ham3 = HiddenAttentionModule(128, 256, stride=2)\n",
    "        self.ham4 = HiddenAttentionModule(256, 512, stride=2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.ham1(x)\n",
    "        x = self.ham2(x)\n",
    "        x = self.ham3(x)\n",
    "        x = self.ham4(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba82d735-d905-42cf-99b1-68a6791a91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Custom Dataset\n",
    "class GaitGAFDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75379ae4-e1fd-4d48-9d49-c7799dbeb871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\mlenv\\gaitenv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb68380-4c1f-415e-bc4b-d29cdeb285ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\mlenv\\gaitenv\\gaf_images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"gaf_images/\")  # Adjust path\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb878ede-7327-4a1b-af6b-58ccc7036c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['als', 'best_ha_resnet.pth', 'control', 'hunt', 'park']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fbded7f-9a7c-430f-bb31-cc2ff976195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of als: ['DoubleSupport', 'DoubleSupport%', 'L_Stance', 'L_Stance%', 'L_Stride', 'L_Swing', 'L_Swing%', 'R_Stance', 'R_Stance%', 'R_Stride', 'R_Swing', 'R_Swing%']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cls_dir = \"als\"  # Try \"ALS\" if lowercase fails\n",
    "if os.path.exists(cls_dir):\n",
    "    print(f\"Contents of {cls_dir}:\", os.listdir(cls_dir))\n",
    "else:\n",
    "    print(f\"{cls_dir} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf89dc12-262c-48ec-8853-3ca1363d2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in als\\L_Stride: 13\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "feature_dir = os.path.join(\"als\", \"L_Stride\")  # Try \"ALS\" if needed\n",
    "if os.path.exists(feature_dir):\n",
    "    images = [f for f in os.listdir(feature_dir) if f.endswith('.png')]\n",
    "    print(f\"Images in {feature_dir}:\", len(images))\n",
    "else:\n",
    "    print(f\"{feature_dir} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d805a0ad-f54f-4f70-a034-041ec23b7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images in: C:\\Users\\piyus\\mlenv\\gaitenv\\gaf_images\n",
      "Loaded 768 images\n",
      "als: 156 images\n",
      "control: 192 images\n",
      "hunt: 240 images\n",
      "park: 180 images\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load and Split Dataset (Fixed)\n",
    "def load_gaf_images(gaf_dir=\".\"):  # Use current directory\n",
    "    classes = {'als': 0, 'control': 1, 'hunt': 2, 'park': 3}\n",
    "    features = [\n",
    "        'L_Stride', 'R_Stride', 'L_Swing', 'R_Swing', 'L_Swing%', 'R_Swing%',\n",
    "        'L_Stance', 'R_Stance', 'L_Stance%', 'R_Stance%', 'DoubleSupport', 'DoubleSupport%'\n",
    "    ]\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    print(f\"Looking for images in: {os.path.abspath(gaf_dir)}\")\n",
    "    if not os.path.exists(gaf_dir):\n",
    "        print(f\"Error: {gaf_dir} directory does not exist\")\n",
    "        return image_paths, labels\n",
    "\n",
    "    for cls_name, cls_idx in classes.items():\n",
    "        cls_dir = os.path.join(gaf_dir, cls_name)\n",
    "        cls_dir_alt = os.path.join(gaf_dir, cls_name.upper())\n",
    "        if os.path.exists(cls_dir):\n",
    "            active_dir = cls_dir\n",
    "        elif os.path.exists(cls_dir_alt):\n",
    "            active_dir = cls_dir_alt\n",
    "            print(f\"Using {cls_name.upper()} instead of {cls_name}\")\n",
    "        else:\n",
    "            print(f\"Error: Neither {cls_dir} nor {cls_dir_alt} found\")\n",
    "            continue\n",
    "\n",
    "        for feature in features:\n",
    "            feature_dir = os.path.join(active_dir, feature)\n",
    "            if not os.path.exists(feature_dir):\n",
    "                print(f\"Warning: {feature_dir} not found\")\n",
    "                continue\n",
    "            for img_name in os.listdir(feature_dir):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img_path = os.path.join(feature_dir, img_name)\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(cls_idx)\n",
    "\n",
    "    print(f\"Loaded {len(image_paths)} images\")\n",
    "    class_counts = Counter(labels)\n",
    "    for cls_name, cls_idx in classes.items():\n",
    "        print(f\"{cls_name}: {class_counts[cls_idx]} images\")\n",
    "    \n",
    "    if len(image_paths) != 768:\n",
    "        print(f\"Warning: Expected 768 images, found {len(image_paths)}. Verify dataset.\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "def split_dataset(image_paths, labels, train_ratio=0.7, val_ratio=0.1):\n",
    "    # Train+Val / Test split\n",
    "    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    # Train / Val split\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_val_paths, train_val_labels, test_size=val_ratio/(train_ratio+val_ratio),\n",
    "        stratify=train_val_labels, random_state=42\n",
    "    )\n",
    "    return train_paths, val_paths, test_paths, train_labels, val_labels, test_labels\n",
    "\n",
    "# Test loading\n",
    "image_paths, labels = load_gaf_images(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98efb7f1-695f-4438-9fdd-323365a775a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images in: C:\\Users\\piyus\\mlenv\\gaitenv\\gaf_images\n",
      "Loaded 768 images\n",
      "als: 156 images\n",
      "control: 192 images\n",
      "hunt: 240 images\n",
      "park: 180 images\n",
      "Train: 537 images, Val: 77 images, Test: 154 images\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Weighted Sampler and DataLoader Setup (with Augmentation)\n",
    "def get_weighted_sampler(labels):\n",
    "    class_counts = Counter(labels)\n",
    "    num_samples = len(labels)\n",
    "    weights = [num_samples / class_counts[label] for label in labels]\n",
    "    sampler = WeightedRandomSampler(weights, num_samples, replacement=True)\n",
    "    return sampler\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and split dataset\n",
    "image_paths, labels = load_gaf_images(\".\")\n",
    "train_paths, val_paths, test_paths, train_labels, val_labels, test_labels = split_dataset(image_paths, labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = GaitGAFDataset(train_paths, train_labels, transform=train_transform)\n",
    "val_dataset = GaitGAFDataset(val_paths, val_labels, transform=val_test_transform)\n",
    "test_dataset = GaitGAFDataset(test_paths, test_labels, transform=val_test_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_sampler = get_weighted_sampler(train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_paths)} images, Val: {len(val_paths)} images, Test: {len(test_paths)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056cba5f-65f0-4f00-b625-907f900b07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Training and Evaluation Functions (Updated for Overfitting Check)\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, patience=5):\n",
    "    best_val_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_true = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = accuracy_score(train_true, train_preds)\n",
    "        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(\n",
    "            train_true, train_preds, average='weighted', zero_division=0)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
    "            val_true, val_preds, average='weighted', zero_division=0\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train - Loss: {epoch_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
    "        print(f\"Unique predicted classes (val): {np.unique(val_preds)}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save(best_model_state, 'best_ha_resnet.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            true.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true, preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    print(f\"Unique predicted classes (test): {np.unique(preds)}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ALS', 'Control', 'Huntington', 'Parkinson'],\n",
    "                yticklabels=['ALS', 'Control', 'Huntington', 'Parkinson'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7344250c-adc0-4490-a2f0-efeb6f5b3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train - Loss: 1.3524, Accuracy: 0.2812, F1: 0.2699\n",
      "Val   - Loss: 1.3981, Accuracy: 0.2338, F1: 0.0886\n",
      "Unique predicted classes (val): [3]\n",
      "Epoch 2/30\n",
      "Train - Loss: 1.2993, Accuracy: 0.3352, F1: 0.3289\n",
      "Val   - Loss: 1.3511, Accuracy: 0.2727, F1: 0.1886\n",
      "Unique predicted classes (val): [0 1 2 3]\n",
      "Epoch 3/30\n",
      "Train - Loss: 1.2819, Accuracy: 0.4060, F1: 0.3910\n",
      "Val   - Loss: 1.3293, Accuracy: 0.4286, F1: 0.3829\n",
      "Unique predicted classes (val): [0 1 2]\n",
      "Epoch 4/30\n",
      "Train - Loss: 1.3035, Accuracy: 0.3762, F1: 0.3708\n",
      "Val   - Loss: 1.2256, Accuracy: 0.4675, F1: 0.4297\n",
      "Unique predicted classes (val): [0 1 2 3]\n",
      "Epoch 5/30\n",
      "Train - Loss: 1.2636, Accuracy: 0.4153, F1: 0.3784\n",
      "Val   - Loss: 1.4440, Accuracy: 0.2857, F1: 0.1886\n",
      "Unique predicted classes (val): [0 1 2]\n",
      "Epoch 6/30\n",
      "Train - Loss: 1.2473, Accuracy: 0.4115, F1: 0.4107\n",
      "Val   - Loss: 1.2967, Accuracy: 0.4156, F1: 0.3645\n",
      "Unique predicted classes (val): [0 1 2 3]\n",
      "Epoch 7/30\n",
      "Train - Loss: 1.2342, Accuracy: 0.4413, F1: 0.3952\n",
      "Val   - Loss: 1.2571, Accuracy: 0.4156, F1: 0.3707\n",
      "Unique predicted classes (val): [0 1 2 3]\n",
      "Epoch 8/30\n",
      "Train - Loss: 1.2314, Accuracy: 0.4264, F1: 0.4100\n",
      "Val   - Loss: 1.3426, Accuracy: 0.3506, F1: 0.3272\n",
      "Unique predicted classes (val): [0 1 2 3]\n",
      "Epoch 9/30\n",
      "Train - Loss: 1.2291, Accuracy: 0.4264, F1: 0.4131\n",
      "Val   - Loss: 1.3172, Accuracy: 0.3377, F1: 0.3193\n",
      "Unique predicted classes (val): [0 1 2 3]\n",
      "Early stopping at epoch 9\n",
      "Test Accuracy: 0.4286\n",
      "Test Precision: 0.4856\n",
      "Test Recall: 0.4286\n",
      "Test F1-Score: 0.4145\n",
      "Unique predicted classes (test): [0 1 2 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 9: Main Execution (with Early Stopping)\n",
    "model = HA_ResNet(num_classes=4).to(device)\n",
    "class_weights = torch.tensor([768/156, 768/192, 768/240, 768/180], dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "num_epochs = 30\n",
    "best_model_state = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, patience=5)\n",
    "model.load_state_dict(torch.load('best_ha_resnet.pth'))\n",
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab88d82-bca1-4e5e-9daf-76d61b8825ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Plot Training and Validation Curves\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    best_val_f1 = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_true = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = accuracy_score(train_true, train_preds)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train - Loss: {epoch_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Unique predicted classes (val): {np.unique(val_preds)}\")\n",
    "\n",
    "        if val_accuracy > best_val_f1:\n",
    "            best_val_f1 = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_ha_resnet.pth')\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Run training\n",
    "model = HA_ResNet(num_classes=4).to(device)\n",
    "class_weights = torch.tensor([768/156, 768/192, 768/240, 768/180], dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "num_epochs = 30\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    ")\n",
    "\n",
    "# Plot curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs+1), val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate best model\n",
    "model.load_state_dict(torch.load('best_ha_resnet.pth'))\n",
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad24ece-2917-434f-b478-e95b89d7d3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
